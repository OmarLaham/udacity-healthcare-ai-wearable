{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Pulse Rate Algorithm\n",
    "\n",
    "### Contents\n",
    "Fill out this notebook as part of your final project submission.\n",
    "\n",
    "**You will have to complete both the Code and Project Write-up sections.**\n",
    "- The [Code](#Code) is where you will write a **pulse rate algorithm** and already includes the starter code.\n",
    "   - Imports - These are the imports needed for Part 1 of the final project. \n",
    "     - [glob](https://docs.python.org/3/library/glob.html)\n",
    "     - [numpy](https://numpy.org/)\n",
    "     - [scipy](https://www.scipy.org/)\n",
    "- The [Project Write-up](#Project-Write-up) to describe why you wrote the algorithm for the specific case.\n",
    "\n",
    "\n",
    "### Dataset\n",
    "You will be using the **Troika**[1] dataset to build your algorithm. Find the dataset under `datasets/troika/training_data`. The `README` in that folder will tell you how to interpret the data. The starter code contains a function to help load these files.\n",
    "\n",
    "1. Zhilin Zhang, Zhouyue Pi, Benyuan Liu, ‘‘TROIKA: A General Framework for Heart Rate Monitoring Using Wrist-Type Photoplethysmographic Signals During Intensive Physical Exercise,’’IEEE Trans. on Biomedical Engineering, vol. 62, no. 2, pp. 522-531, February 2015. Link\n",
    "\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary for me!\n",
    "#ecg | ppg1| ppg2 | accx | accy | accz\n",
    "#For datasets with names containing 'TYPE01', the running speeds changed as follows:\n",
    "#    rest(30s) -> 8km/h(1min) -> 15km/h(1min) -> 8km/h(1min) -> 15km/h(1min) -> rest(30s)\n",
    "\n",
    "#For datasets with names containing 'TYPE02', the running speeds changed as follows:\n",
    "#    rest(30s) -> 6km/h(1min) -> 12km/h(1min) -> 6km/h(1min) -> 12km/h(1min) -> rest(30s)\n",
    "\n",
    "#For each dataset with the similar name 'DATA_01_TYPE01', the ground-truth of heart rate can be  /\n",
    "#calculated from the simultaneously recorded ECG signal (i.e. the first row of the variable 'sig')\n",
    "\n",
    "#For convenience, we also provide the calculated ground-truth heart rate, stored in the datasets with the /\n",
    "#corresponding name, say 'REF_01_TYPE01'.\n",
    "\n",
    "#In each of this kind of datasets, there is a variable 'BPM0', /\n",
    "# which gives the BPM value in every 8-second time window\n",
    "\n",
    "#Note that two successive time windows overlap by 6 seconds. Thus the first value in 'BPM0' gives /\n",
    "#the calcualted heart rate ground-truth in the first 8 seconds, while the second value in 'BPM0' gives /\n",
    "#the calculated heart rate ground-truth from the 3rd second to the 10th second.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%matplotlib inline <- #commented just for testing\n",
    "\n",
    "import glob\n",
    "\n",
    "import math\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import scipy.signal\n",
    "import scipy.stats as st\n",
    "import scipy.io\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import LeaveOneGroupOut\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "def BandpassFilter(signal, pass_band, fs):\n",
    "    \"\"\"Bandpass Filter.\n",
    "    \n",
    "    Args:\n",
    "        signal: (np.array) The input signal\n",
    "        pass_band: (tuple) The pass band. Frequency components outside \n",
    "            the two elements in the tuple will be removed.\n",
    "        fs: (number) The sampling rate of <signal>\n",
    "        \n",
    "    Returns:\n",
    "        (np.array) The filtered signal\n",
    "    \"\"\"\n",
    "    b, a = sp.signal.butter(3, pass_band, btype='bandpass', fs=fs)\n",
    "    return sp.signal.filtfilt(b, a, signal)\n",
    "\n",
    "def PlotSpecgram(signal, t, fs, nfft, noverlap, figsize, num_rows, col_num):\n",
    "    \"\"\"Specgram\n",
    "    \n",
    "    Args:\n",
    "        signal: (np.array) The input signal to plot specgram for\n",
    "        T: (number) The time in seconds of <signal>\n",
    "        fs: (number) The sampling rate of <signal>\n",
    "        num_rows: (number) The number of the rows in plot grid when specgram plots are aggregated.\n",
    "        col_num: (number) The number of the column in plot grid when specgram plots are aggregated.\n",
    "        \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.subplot(num_rows,1,col_num)\n",
    "    plt.title('Spectrogram')\n",
    "    plt.specgram(signal, Fs=fs, NFFT=nfft, noverlap=noverlap, xextent=((0, t)))\n",
    "    plt.xlabel('Time (sec)')\n",
    "    plt.ylabel('Frequency (Hz)')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return None\n",
    "\n",
    "def GetDomAccFreq(accx, accy, accz, fs):\n",
    "    \n",
    "    \"\"\"Get Dominant Acc Frequency\n",
    "    \n",
    "    Args:\n",
    "        accx: (np.array) The input signal of accx\n",
    "        accy: (np.array) The input signal of accy\n",
    "        accz: (np.array) The input signal of accz\n",
    "        fs: (number) The sampling rate of <accx, accy, accz> which must be the same\n",
    "        \n",
    "    Returns:\n",
    "        acc_dom_freq: (float) The max of main frequencies in accx, accy and accz signals.\n",
    "        acc_dom_freqs: (np.array) The freqs of the acc in the orientation of the dominant frequency.\n",
    "        acc_dom_mag: (np.array) The absolute amplitudes of the acc in the orientation of the dominant frequency.\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    accx_freqs = np.fft.rfftfreq(len(accx), 1/fs)\n",
    "    accx_fft = np.fft.rfft(accx)\n",
    "    accx_mag = np.abs(accx_fft)\n",
    "    accx_main_freq = accx_freqs[np.argmax(accx_mag)]\n",
    "\n",
    "    accy_freqs = np.fft.rfftfreq(len(accy), 1/fs)\n",
    "    accy_fft = np.fft.rfft(accy)\n",
    "    accy_mag = np.abs(accy_fft)\n",
    "    accy_main_freq = accy_freqs[np.argmax(accy_mag)]\n",
    "\n",
    "    accz_freqs = np.fft.rfftfreq(len(accz), 1/fs)\n",
    "    accz_fft = np.fft.rfft(accz)\n",
    "    accz_mag = np.abs(accz_fft)\n",
    "    accz_main_freq = accz_freqs[np.argmax(accz_mag)]\n",
    "\n",
    "\n",
    "    acc_dom_freq = max([accx_main_freq, accy_main_freq, accz_main_freq])\n",
    "    \n",
    "    #dominant_acc\n",
    "    acc_dom = \"\"\n",
    "    acc_dom_freqs = None\n",
    "    acc_dom_fft = None\n",
    "    acc_dom = None\n",
    "\n",
    "    if acc_dom_freq == accx_main_freq:\n",
    "        acc_dom = \"x\"\n",
    "        acc_dom_freqs = accx_freqs\n",
    "        acc_dom_fft = accx_fft\n",
    "        acc_dom = accx\n",
    "    elif acc_dom_freq == accy_main_freq:\n",
    "        acc_dom = \"y\"\n",
    "        acc_dom_freqs = accy_freqs\n",
    "        acc_dom_fft = accy_fft\n",
    "        acc_dom = accy\n",
    "    else:\n",
    "        acc_dom = \"z\"\n",
    "        acc_dom_freqs = accz_freqs\n",
    "        acc_dom_fft = accz_fft\n",
    "        acc_dom = accz\n",
    "\n",
    "\n",
    "    return acc_dom_freq, acc_dom_freqs, acc_dom_fft, acc_dom\n",
    "\n",
    "def FilterWindowTolerance(ppg, acc_dom_freq, tolerance):  \n",
    "    \n",
    "    \"\"\"Filter PPG Using a Tolerance Window\n",
    "    \n",
    "    Args:\n",
    "        ppg: (np.array) The <ppg> signal\n",
    "        acc_dom_freq: (float) The dominant freq of all acc input.\n",
    "        tolerance: (float) The half width of the  window centered by acc_dom_freq where peaks will be filtered out.\n",
    "        fs: (number) The sampling rate of <accx, accy, accz> which must be the same.\n",
    "        \n",
    "    Returns:\n",
    "        ppg: (np.array) The ppg signal filtered using tolerance value\n",
    "    \"\"\"\n",
    "    \n",
    "    ppg = ppg[((np.abs(ppg) < abs(acc_dom_freq - tolerance))) | ((np.abs(ppg) > abs(acc_dom_freq + tolerance)))]\n",
    "    return ppg\n",
    "\n",
    "def LoadTroikaDataset():\n",
    "    \"\"\"\n",
    "    Retrieve the .mat filenames for the troika dataset.\n",
    "\n",
    "    Review the README in ./datasets/troika/ to understand the organization of the .mat files.\n",
    "\n",
    "    Returns:\n",
    "        data_fls: Names of the .mat files that contain signal data\n",
    "        ref_fls: Names of the .mat files that contain reference data\n",
    "        <data_fls> and <ref_fls> are ordered correspondingly, so that ref_fls[5] is the \n",
    "            reference data for data_fls[5], etc...\n",
    "    \"\"\"\n",
    "    data_dir = \"./datasets/troika/training_data\"\n",
    "    data_fls = sorted(glob.glob(data_dir + \"/DATA_*.mat\"))\n",
    "    ref_fls = sorted(glob.glob(data_dir + \"/REF_*.mat\"))\n",
    "    return data_fls, ref_fls\n",
    "\n",
    "def LoadTroikaDataFile(data_fl):\n",
    "    \"\"\"\n",
    "    Loads and extracts signals from a troika data file.\n",
    "\n",
    "    Usage:\n",
    "        data_fls, ref_fls = LoadTroikaDataset()\n",
    "        ppg, accx, accy, accz = LoadTroikaDataFile(data_fls[0])\n",
    "\n",
    "    Args:\n",
    "        data_fl: (str) filepath to a troika .mat file.\n",
    "\n",
    "    Returns:\n",
    "        numpy arrays for ppg, accx, accy, accz signals.\n",
    "    \"\"\"\n",
    "    data = sp.io.loadmat(data_fl)['sig']\n",
    "    return data[2:]\n",
    "\n",
    "def AggregateErrorMetric(pr_errors, confidence_est):\n",
    "    \"\"\"\n",
    "    Computes an aggregate error metric based on confidence estimates.\n",
    "\n",
    "    Computes the MAE at 90% availability. \n",
    "\n",
    "    Args:\n",
    "        pr_errors: a numpy array of errors between pulse rate estimates and corresponding \n",
    "            reference heart rates.\n",
    "        confidence_est: a numpy array of confidence estimates for each pulse rate\n",
    "            error.\n",
    "\n",
    "    Returns:\n",
    "        the MAE at 90% availability\n",
    "    \"\"\"\n",
    "    # Higher confidence means a better estimate. The best 90% of the estimates\n",
    "    #    are above the 10th percentile confidence.\n",
    "    percentile90_confidence = np.percentile(confidence_est, 10)\n",
    "\n",
    "    # Find the errors of the best pulse rate estimates\n",
    "    best_estimates = pr_errors[confidence_est >= percentile90_confidence]\n",
    "\n",
    "    # Return the mean absolute error\n",
    "    return np.mean(np.abs(best_estimates))\n",
    "\n",
    "def Evaluate(tolerance = 0.6, sig_diff_interval = 25):\n",
    "    \"\"\"\n",
    "    Top-level function evaluation function.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns an aggregate error metric.\n",
    "\n",
    "    Args:\n",
    "        tolerance: (float) the tolerance to be passed to FilterWindowTolerance through RunPulseRateAlgorithm\n",
    "        sig_diff_interval: (int) the interval used to create a window to compare PPG and ACC signal power around a peak passed to RunPulseRateAlgorithm.\n",
    "    \n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    # Retrieve dataset files\n",
    "    data_fls, ref_fls = LoadTroikaDataset()\n",
    "    errs, confs = [], []\n",
    "    for data_fl, ref_fl in zip(data_fls, ref_fls):\n",
    "        print(\"Evaluating: \" + data_fl + \"...\")\n",
    "        # Run the pulse rate algorithm on each trial in the dataset\n",
    "        errors, confidence = RunPulseRateAlgorithm(data_fl, ref_fl, tolerance)\n",
    "        errs.append(errors)\n",
    "        confs.append(confidence)\n",
    "    # Compute aggregate error metric\n",
    "        \n",
    "    errs = np.hstack(errs)\n",
    "    confs = np.hstack(confs)\n",
    "    \n",
    "    return AggregateErrorMetric(errs, confs)\n",
    "\n",
    "def RunPulseRateAlgorithm(data_fl, ref_fl, tolerance = 0.6, sig_diff_interval = 25):\n",
    "    \n",
    "    \"\"\"\n",
    "    Top-level function that runs our HR detection algorithm.\n",
    "\n",
    "    Runs the pulse rate algorithm on the Troika dataset and returns errors and confidence estimates.\n",
    "\n",
    "    Args:\n",
    "        data_fl (str): name for the data file including GGP and ACC signals.\n",
    "        ref_fl (str): name for the data file including the reference heart beat per minute.\n",
    "        tolerance: (float) the tolerance to be passed to FilterWindowTolerance. Default = 0.6\n",
    "        sig_diff_interval: (int) the interval used to create a window to compare PPG and ACC signal power around a peak.\n",
    "    \n",
    "    Returns:\n",
    "        Pulse rate error on the Troika dataset. See AggregateErrorMetric.\n",
    "    \"\"\"\n",
    "    \n",
    "    fs = 125\n",
    "    time_seconds = 5 * 60\n",
    "    # Window to calculate reference pulse rate\n",
    "    win_len = 8 * fs #window of 8s\n",
    "    \n",
    "    win_shift = 2 * fs # windows shift of 2s\n",
    "    \n",
    "    #params for general plotting\n",
    "    loop_n_plots = 1\n",
    "    figsize = (12, 15 * loop_n_plots)\n",
    "    \n",
    "    #params for specgram \n",
    "    plot_specgram = False\n",
    "    nfft = 250\n",
    "    noverlap = 6\n",
    "    \n",
    "    ref_overlap = 3 #3s\n",
    "    \n",
    "    if plot_specgram:\n",
    "        loop_n_plots += 8\n",
    "    \n",
    "\n",
    "    \n",
    "    #param for bandpass using the min and max bpm accoring to criteria.\n",
    "    ppg_pass_band = (40/60, 240/60)\n",
    "    acc_pass_band = (40/60, 240/60)\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Load data using LoadTroikaDataFile\n",
    "    full_ppg, full_accx, full_accy, full_accz = LoadTroikaDataFile(data_fl)\n",
    "    full_ref_bpm = sp.io.loadmat(ref_fl)['BPM0'].flatten()\n",
    "    full_ref_n_samples = len(full_ref_bpm)\n",
    "    \n",
    "    plt_idx = 1\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    #plot specgram before bandpass\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_ppg, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed), i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    #apply bandpass to ppg signal\n",
    "    full_ppg = BandpassFilter(full_ppg, ppg_pass_band, fs)\n",
    "    #plot specgram after bandpass\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_ppg, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed), i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "\n",
    "    #apply bandpass to accx signal\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_accx, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed), i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    full_accx = BandpassFilter(full_accx, acc_pass_band, fs)\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_accx, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed), i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    #apply bandpass to accy signal\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_accy, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed), i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    full_accy = BandpassFilter(full_accy, acc_pass_band, fs)\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_accy, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed), i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    #apply bandpass to accz signal\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_accz, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed),i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    full_accz = BandpassFilter(full_accz, acc_pass_band, fs)\n",
    "    if plot_specgram:\n",
    "        PlotSpecgram(full_accz, time, fs, nfft, noverlap, figsize, loop_n_plots * len(time_speed),i * loop_n_plots + plt_idx)\n",
    "        plt_idx += 1\n",
    "    \n",
    "    # Compute pulse rate estimates and estimation confidence.\n",
    "    \n",
    "    #######################should be errs\n",
    "    preds, errs, confs = [], [], []\n",
    "\n",
    "    #ws: window start\n",
    "    #we: window end\n",
    "    win_idx = 0\n",
    "    ws = 0 - win_shift\n",
    "    we = None\n",
    "    \n",
    "    #ws is window start index\n",
    "    for ws in range(0, len(full_ppg) - win_len, win_shift):\n",
    "        \n",
    "        if win_idx % 45 == 0 and win_idx > 0:\n",
    "            print(\"reached window index\", win_idx)\n",
    "\n",
    "        #we is window end index\n",
    "        we = ws + win_len     \n",
    "            \n",
    "        #find ppg corresponding window\n",
    "        ppg_window = full_ppg[ws:we]\n",
    "        \n",
    "        #find dominant acc\n",
    "        acc_dom_freq, acc_freqs, acc_fft, acc = GetDomAccFreq(full_accx, full_accy, full_accz, fs)\n",
    "        \n",
    "        #find acc corresponding window\n",
    "        acc_window = acc[ws:we]\n",
    "        \n",
    "        #ppg fft\n",
    "        ppg_fft = np.abs(np.fft.rfft(ppg_window, 2 * len(ppg_window)))\n",
    "        ppg_freqs = np.fft.rfftfreq(2 * len(ppg_window), 1/fs)\n",
    "        \n",
    "        #acc fft\n",
    "        acc_fft = np.abs(np.fft.rfft(acc_window, 2 * len(acc_window)))\n",
    "        acc_freqs = np.fft.rfftfreq(2 * len(acc_window), 1/fs)\n",
    "        \n",
    "        \n",
    "        # filter the signals\n",
    "        ppg_fft[ppg_freqs <= (40)/60.0] = 0.0\n",
    "        ppg_fft[ppg_freqs >= (240)/60.0] = 0.0\n",
    "\n",
    "        acc_fft[acc_freqs <= (40)/60.0] = 0.0\n",
    "        acc_fft[acc_freqs >= (240)/60.0] = 0.0\n",
    "        \n",
    "        #find strongest n =  3 freqs in window with indecies\n",
    "        \n",
    "        # start with the maximum and iterate\n",
    "        ppg_max = ppg_freqs[np.argsort(ppg_fft, axis=0)[-1]]\n",
    "        acc_max = acc_freqs[np.argsort(acc_fft, axis=0)[-1]]\n",
    "\n",
    "        n = 3\n",
    "        for i in range(1, n+1):\n",
    "            ppg_max_tmp = ppg_freqs[np.argsort(ppg_fft, axis=0)[-i]]\n",
    "            acc_max_tmp = acc_freqs[np.argsort(acc_fft, axis=0)[-i]]\n",
    "\n",
    "            if ppg_freqs[np.argsort(ppg_fft, axis=0)[-i]] < ppg_max:\n",
    "                ppg_max = ppg_freqs[np.argsort(ppg_fft, axis=0)[-i]]\n",
    "\n",
    "            if acc_freqs[np.argsort(acc_fft, axis=0)[-i]] < acc_max:\n",
    "                acc_max = acc_freqs[np.argsort(acc_fft, axis=0)[-i]]\n",
    "            \n",
    "        #estimation (or prediction)\n",
    "        est = ppg_max * 60\n",
    "        preds.append(est)\n",
    "        err = abs(est - full_ref_bpm[win_idx])\n",
    "        errs.append(err)\n",
    "                \n",
    "       \n",
    "        #calculate confidence\n",
    "        #fs_win = min_accepted_bpm / 60(s)\n",
    "        fs_win = 40  / 60.0\n",
    "        fs_win_e = (ppg_freqs >= ppg_max - fs_win) & (ppg_freqs <= ppg_max +fs_win)\n",
    "        conf = np.sum(ppg_fft[fs_win_e])/np.sum(ppg_fft)\n",
    "        confs.append(conf)\n",
    "    \n",
    "        \n",
    "        win_idx += 1\n",
    "        \n",
    "    # Return per-estimate mean absolute error and confidence as a 2-tuple of numpy arrays.\n",
    "    #check length of subtracted arrays so we don't get out of bounds\n",
    "    comparison_length = min(len(full_ref_bpm), len(preds))\n",
    "    errors = np.array(errs)\n",
    "    return errors, np.array(confs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean absolute error at 90% availability = 24.935058048941524\n"
     ]
    },
   ],
   "source": [
    "mae_90 = Evaluate()\n",
    "print(\"===========================================\")\n",
    "print(\"The mean absolute error at 90% availability = {0}\".format(mae_90))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Project Write-up\n",
    "\n",
    "Answer the following prompts to demonstrate understanding of the algorithm you wrote for this specific context.\n",
    "\n",
    "> - **Code Description**\n",
    "The main work is in the RunPulseRateAlgorithm function we calculate pulse rate using GGP signal and correct the prediction using the ACC signal.\n",
    "<br />\n",
    "The Evaluate function runs the algorithm on the train data and measures the mean absolute error and confidence of the output so we can use them as performance metrics.\n",
    "<br />\n",
    "> - **Data Description** - \n",
    "We are using the Troika dataset. Two-channel PPG signals, three-axis acceleration signals, and one-channel ECG signals were\n",
    "simultaneously recorded from subjects with age from 18 to 35. All signals were sampled at 125 Hz and sent to a nearby computer via\n",
    "Bluetooth.\n",
    "<br />\n",
    "Each dataset with the similar name 'DATA_01_TYPE01' contains a variable 'sig'. It has 6 rows. The first row is a simultaneous recording of ECG, which is recorded from the chest of each subject.\n",
    "<br />\n",
    "The second row and the third row are two channels of PPG, which are recorded from the wrist of each\n",
    "subject. The last three rows are simultaneous recordings of acceleration data (in x-, y-, and z-axis).\n",
    "<br />\n",
    "For datasets with names containing 'TYPE01', the running speeds changed as follows:\n",
    "<br />\n",
    "rest(30s) -> 8km/h(1min) -> 15km/h(1min) -> 8km/h(1min) -> 15km/h(1min) -> rest(30s)\n",
    "<br />\n",
    "For datasets with names containing 'TYPE02', the running speeds changed as follows:\n",
    "<br />\n",
    "rest(30s) -> 6km/h(1min) -> 12km/h(1min) -> 6km/h(1min) -> 12km/h(1min) -> rest(30s)\n",
    "<br />\n",
    "For each dataset with the similar name 'DATA_01_TYPE01', the ground-truth of heart rate can be\n",
    "calculated from the simultaneously recorded ECG signal (i.e. the first row of the variable 'sig'). For\n",
    "convenience, we also provide the calculated ground-truth heart rate, stored in the datasets with the\n",
    "corresponding name, say 'REF_01_TYPE01'. In each of this kind of datasets, there is a variable 'BPM0',\n",
    "which gives the BPM value in every 8-second time window.\n",
    "\n",
    "> - **Algorithhm Description** will include the following:\n",
    ">   - how the algorithm works: \n",
    "We start with applying a bandpass filter to the 4 signals after plotting the specgram. We process the signals according to the time periods mentioned above in the dataset section. for estimations, we use a window of 8s length with 2s shift. We find the dominant acc signal and with a tolerance window. After that we find the n = 3 highest freqs in ppg and acc and get the closest freq to them in our window. from there we compute the pr for this window.\n",
    "<br />\n",
    "We calculate estimation confidence for every window depending on the ratio of the energy in the fundemental frequency window to the energy sum in all the window. Then we calcuate the absolute value for the difference between our predictions and the ground truth values. Then Then we compute an aggregate error metric based on confidence estimates. We computes the MAE at 90% availability. finally we return errors and condidence estimations to be aggregated for evaluation.\n",
    ">   - the specific aspects of the physiology that it takes advantage of\n",
    "A PPG sensor will get less reflected light when the vessels have more RBCs (Systolic phase). However, this could be missed with moving the arm. and combining output from PPG and ACC (accelometer) makes predictions much better.\n",
    ">   - a describtion of the algorithm outputs: Described above\n",
    ">   - caveats on algorithm outputs: The output is a result stacked from windows with length of 8s and shift of 2s and they result from 6 different phases (rest, run, run, run, run, rest).\n",
    ">   - common failure modes\n",
    "> - **Algorithm Performance** - Performance was computed using the MAE at 90% availability metric was used for optimization and it's based on confidence estimates caclulated usign the difference in energy spectrum between PPG and ACC data. All data from training data set has been used, but the algorithm will be tested on the test set, too. For training, the main thing was to tune the fundemental window of each window to calculate signal power. For MAE at 90%, and from the project overview: \"There is a trade-off between availability and error. For example, if we want to operate at 10% availability, we look at our training dataset to determine the confidence threshold for which 10% of the estimates pass. Then if only if an estimate's confidence value is above that threshold, do we consider it valid\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----\n",
    "### Next Steps\n",
    "You will now go to **Test Your Algorithm** to apply a unit test to confirm that your algorithm met the success criteria. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
